import 'dart:async';
import 'dart:typed_data';
import 'package:record/record.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:just_audio/just_audio.dart';

/// ì˜¤ë””ì˜¤ ë…¹ìŒ ë° ì¬ìƒ ì„œë¹„ìŠ¤
/// PCM16 í¬ë§·ìœ¼ë¡œ ë…¹ìŒí•˜ê³  WebSocketìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
class AudioService {
  final AudioRecorder _recorder = AudioRecorder();
  late final AudioPlayer _player;

  bool _isRecording = false;
  bool _isPlaying = false;

  StreamSubscription<Uint8List>? _recordingSubscription;
  final StreamController<Uint8List> _audioStreamController =
      StreamController<Uint8List>.broadcast();

  /// ì¬ìƒ ì™„ë£Œ ìŠ¤íŠ¸ë¦¼ (ë²„í¼ê°€ ë¹„ê³  ì¬ìƒì´ ì™„ì „íˆ ëë‚¬ì„ ë•Œ)
  final StreamController<void> _playbackCompletedController =
      StreamController<void>.broadcast();

  /// ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ (ë…¹ìŒëœ ë°ì´í„°)
  Stream<Uint8List> get audioStream => _audioStreamController.stream;

  /// ì¬ìƒ ì™„ë£Œ ìŠ¤íŠ¸ë¦¼ (ì—ì½” ë°©ì§€ë¥¼ ìœ„í•´ ì¬ìƒì´ ì™„ë£Œëœ í›„ì—ë§Œ ì˜¤ë””ì˜¤ ì „ì†¡ ì¬ê°œ)
  Stream<void> get playbackCompletedStream => _playbackCompletedController.stream;

  /// ë…¹ìŒ ìƒíƒœ
  bool get isRecording => _isRecording;

  /// ì¬ìƒ ìƒíƒœ
  bool get isPlaying => _isPlaying;

  /// ì˜¤ë””ì˜¤ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
  Future<void> initialize() async {
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    final hasPermission = await requestPermission();
    if (!hasPermission) {
      throw Exception('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤');
    }

    // AudioPlayer ì´ˆê¸°í™” - ì˜¤ë””ì˜¤ í¬ì»¤ìŠ¤ë¥¼ ìš”ì²­í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
    // ì´ë ‡ê²Œ í•˜ë©´ ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒì´ ê³„ì†ë©ë‹ˆë‹¤
    _player = AudioPlayer(
      // Androidì—ì„œ ì˜¤ë””ì˜¤ í¬ì»¤ìŠ¤ë¥¼ ìš”ì²­í•˜ì§€ ì•ŠìŒ
      // ì´ë¥¼ í†µí•´ ë…¹ìŒê³¼ ì¬ìƒì´ ë™ì‹œì— ê°€ëŠ¥
      handleAudioSessionActivation: false,
    );

    print('âœ… AudioService ì´ˆê¸°í™” ì™„ë£Œ (ì˜¤ë””ì˜¤ í¬ì»¤ìŠ¤ ë¹„í™œì„±í™”)');
  }

  /// ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
  Future<bool> requestPermission() async {
    final status = await Permission.microphone.request();
    return status.isGranted;
  }

  /// ë…¹ìŒ ì‹œì‘ (PCM16 í¬ë§·)
  ///
  /// OpenAI Realtime APIëŠ” PCM16 í¬ë§·ì„ ìš”êµ¬
  /// - Sample Rate: 24000 Hz (24 kHz)
  /// - Channels: 1 (Mono)
  /// - Encoding: PCM16 (16-bit)
  Future<void> startRecording() async {
    if (_isRecording) {
      print('ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤');
      return;
    }

    // ê¶Œí•œ í™•ì¸
    final hasPermission = await requestPermission();
    if (!hasPermission) {
      throw Exception('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤');
    }

    try {
      // ë…¹ìŒ ì‹œì‘
      final stream = await _recorder.startStream(const RecordConfig(
        encoder: AudioEncoder.pcm16bits,
        sampleRate: 24000, // 24 kHz (OpenAI Realtime API ìš”êµ¬ì‚¬í•­)
        numChannels: 1, // Mono
        autoGain: true,
        echoCancel: true, // ì—ì½” ìº”ìŠ¬ í™œì„±í™” (ì•ˆë“œë¡œì´ë“œ ê¸°ë³¸ ê¸°ëŠ¥)
        noiseSuppress: true, // ë…¸ì´ì¦ˆ ì œê±° í™œì„±í™”
      ));

      _isRecording = true;
      print('ğŸ¤ ë…¹ìŒ ì‹œì‘ (PCM16, 24kHz, Mono)');

      // ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ ì „ë‹¬
      int chunkCount = 0;
      _recordingSubscription = stream.listen(
        (audioChunk) {
          chunkCount++;
          if (chunkCount <= 5 || chunkCount % 100 == 0) {
            print('ğŸ¤ ë…¹ìŒ ì²­í¬ #$chunkCount: ${audioChunk.length} bytes');
          }
          _audioStreamController.add(audioChunk);
        },
        onError: (error) {
          print('âŒ ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬: $error');
        },
        onDone: () {
          print('âš ï¸ ë…¹ìŒ ìŠ¤íŠ¸ë¦¼ ì™„ë£Œë¨ (ì´ $chunkCount ì²­í¬)');
        },
        cancelOnError: false,
      );
    } catch (e) {
      print('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
      _isRecording = false;
      rethrow;
    }
  }

  /// ë…¹ìŒ ì¤‘ì§€
  Future<void> stopRecording() async {
    if (!_isRecording) {
      print('ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
      return;
    }

    try {
      await _recordingSubscription?.cancel();
      await _recorder.stop();
      _isRecording = false;
      print('ë…¹ìŒ ì¤‘ì§€');
    } catch (e) {
      print('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨: $e');
      rethrow;
    }
  }

  // ì˜¤ë””ì˜¤ ë²„í¼ (ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ëˆ„ì )
  final List<Uint8List> _audioBuffer = [];
  bool _isProcessingBuffer = false;
  Timer? _bufferFlushTimer;  // ë²„í¼ í”ŒëŸ¬ì‹œ íƒ€ì´ë¨¸

  // ì „ì²´ ì‘ë‹µì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” ë²„í¼
  final List<Uint8List> _fullResponseBuffer = [];
  bool _isCollectingResponse = false;

  // ë²„í¼ë§ ì„¤ì • - ì „ì²´ ì‘ë‹µ ìˆ˜ì§‘ í›„ í•œ ë²ˆì— ì¬ìƒ
  static const Duration _responseEndDelay = Duration(milliseconds: 300);  // ì‘ë‹µ ì¢…ë£Œ ê°ì§€ ì§€ì—°

  /// ì˜¤ë””ì˜¤ ì¬ìƒ (PCM16 ë°”ì´íŠ¸ ë°ì´í„°)
  ///
  /// OpenAI Realtime APIë¡œë¶€í„° ë°›ì€ PCM16 ì˜¤ë””ì˜¤ë¥¼ ë²„í¼ì— ì¶”ê°€
  Future<void> playAudio(Uint8List pcm16Data) async {
    try {
      // ì „ì²´ ì‘ë‹µ ë²„í¼ì— ì¶”ê°€
      _fullResponseBuffer.add(pcm16Data);
      _isCollectingResponse = true;

      // ë²„í¼ í”ŒëŸ¬ì‹œ íƒ€ì´ë¨¸ ì·¨ì†Œ ë° ì¬ì„¤ì •
      _bufferFlushTimer?.cancel();

      // 300ms ë™ì•ˆ ìƒˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‘ë‹µ ì¢…ë£Œë¡œ íŒë‹¨í•˜ê³  ì¬ìƒ
      _bufferFlushTimer = Timer(_responseEndDelay, () {
        if (_fullResponseBuffer.isNotEmpty && !_isProcessingBuffer) {
          _playFullResponse();
        }
      });
    } catch (e) {
      print('âš ï¸ ì˜¤ë””ì˜¤ ë²„í¼ë§ ì‹¤íŒ¨: $e');
    }
  }

  /// ì „ì²´ ì‘ë‹µ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì¬ìƒ
  Future<void> _playFullResponse() async {
    if (_isProcessingBuffer) return;
    _isProcessingBuffer = true;
    _isCollectingResponse = false;

    try {
      // ì „ì²´ ë²„í¼ í•©ì¹˜ê¸°
      final totalLength = _fullResponseBuffer.fold<int>(
        0, (sum, chunk) => sum + chunk.length,
      );

      if (totalLength == 0) {
        _isProcessingBuffer = false;
        return;
      }

      final fullAudio = Uint8List(totalLength);
      int offset = 0;
      for (final chunk in _fullResponseBuffer) {
        fullAudio.setRange(offset, offset + chunk.length, chunk);
        offset += chunk.length;
      }
      _fullResponseBuffer.clear();

      print('ğŸ”Š ì „ì²´ ì‘ë‹µ ì˜¤ë””ì˜¤ ì¬ìƒ: ${fullAudio.length} bytes (${(fullAudio.length / 48000).toStringAsFixed(1)}ì´ˆ)');

      // PCM16ì„ WAVë¡œ ë³€í™˜
      final wavData = _convertPcm16ToWav(fullAudio);

      // ì¬ìƒ
      await _player.setAudioSource(
        AudioSource.uri(
          Uri.dataFromBytes(wavData, mimeType: 'audio/wav'),
        ),
      );

      _isPlaying = true;
      await _player.play();

      // ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
      await _player.playerStateStream.firstWhere(
        (state) => state.processingState == ProcessingState.completed,
      );

      _isPlaying = false;

      // ì¬ìƒ ì¤‘ì— ìƒˆ ë°ì´í„°ê°€ ë“¤ì–´ì™”ìœ¼ë©´ ë‹¤ì‹œ ì¬ìƒ
      if (_fullResponseBuffer.isNotEmpty) {
        _isProcessingBuffer = false;
        _playFullResponse();
        return;
      }

      // ëª¨ë“  ì¬ìƒ ì™„ë£Œ - ì½œë°± í˜¸ì¶œ
      print('ğŸ”Š ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ - playbackCompletedStream ë°œì†¡');
      _playbackCompletedController.add(null);
    } catch (e) {
      print('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e');
      _isPlaying = false;
      _fullResponseBuffer.clear();
      _playbackCompletedController.add(null);
    } finally {
      _isProcessingBuffer = false;
    }
  }

  /// ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì¬ìƒ (ë ˆê±°ì‹œ - ì‚¬ìš© ì•ˆí•¨)
  Future<void> _processAudioBuffer() async {
    // ì´ ë©”ì„œë“œëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
  }

  /// ë²„í¼ì˜ ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
  Uint8List _combineAudioBuffers() {
    if (_audioBuffer.isEmpty) return Uint8List(0);

    final totalLength = _audioBuffer.fold<int>(
      0,
      (sum, buffer) => sum + buffer.length,
    );

    final combined = Uint8List(totalLength);
    int offset = 0;

    for (final buffer in _audioBuffer) {
      combined.setRange(offset, offset + buffer.length, buffer);
      offset += buffer.length;
    }

    return combined;
  }

  /// PCM16 ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ë³€í™˜
  ///
  /// [pcm16Data]: PCM16 ì˜¤ë””ì˜¤ ë°ì´í„°
  /// Returns: WAV í¬ë§· ë°”ì´íŠ¸ ë°ì´í„° (í—¤ë” í¬í•¨)
  Uint8List _convertPcm16ToWav(Uint8List pcm16Data) {
    final int sampleRate = 24000;
    final int numChannels = 1;
    final int bitsPerSample = 16;
    final int byteRate = sampleRate * numChannels * bitsPerSample ~/ 8;
    final int blockAlign = numChannels * bitsPerSample ~/ 8;
    final int dataSize = pcm16Data.length;
    final int fileSize = 36 + dataSize;

    final BytesBuilder builder = BytesBuilder();

    // RIFF í—¤ë”
    builder.add(utf8Encode('RIFF'));
    builder.add(_int32ToBytes(fileSize));
    builder.add(utf8Encode('WAVE'));

    // fmt ì„œë¸Œì²­í¬
    builder.add(utf8Encode('fmt '));
    builder.add(_int32ToBytes(16)); // fmt ì²­í¬ í¬ê¸°
    builder.add(_int16ToBytes(1)); // PCM í¬ë§·
    builder.add(_int16ToBytes(numChannels));
    builder.add(_int32ToBytes(sampleRate));
    builder.add(_int32ToBytes(byteRate));
    builder.add(_int16ToBytes(blockAlign));
    builder.add(_int16ToBytes(bitsPerSample));

    // data ì„œë¸Œì²­í¬
    builder.add(utf8Encode('data'));
    builder.add(_int32ToBytes(dataSize));
    builder.add(pcm16Data);

    return builder.toBytes();
  }

  /// UTF-8 ì¸ì½”ë”© í—¬í¼
  List<int> utf8Encode(String str) {
    return str.codeUnits;
  }

  /// int32ë¥¼ Little Endian ë°”ì´íŠ¸ë¡œ ë³€í™˜
  List<int> _int32ToBytes(int value) {
    return [
      value & 0xFF,
      (value >> 8) & 0xFF,
      (value >> 16) & 0xFF,
      (value >> 24) & 0xFF,
    ];
  }

  /// int16ë¥¼ Little Endian ë°”ì´íŠ¸ë¡œ ë³€í™˜
  List<int> _int16ToBytes(int value) {
    return [
      value & 0xFF,
      (value >> 8) & 0xFF,
    ];
  }

  /// MP3 ì˜¤ë””ì˜¤ ì¬ìƒ (í™˜ì˜ ë©”ì‹œì§€ìš©)
  ///
  /// [mp3Data]: MP3 ë°”ì´íŠ¸ ë°ì´í„°
  Future<void> playMp3Audio(Uint8List mp3Data) async {
    try {
      // MP3 ë°ì´í„°ë¥¼ Data URIë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ
      await _player.setAudioSource(
        AudioSource.uri(
          Uri.dataFromBytes(mp3Data, mimeType: 'audio/mpeg'),
        ),
      );

      _isPlaying = true;
      await _player.play();

      // ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
      await _player.playerStateStream.firstWhere(
        (state) => state.processingState == ProcessingState.completed,
      );

      _isPlaying = false;
    } catch (e) {
      print('âš ï¸ MP3 ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e');
      _isPlaying = false;
      // ì—ëŸ¬ë¥¼ ì „íŒŒí•˜ì§€ ì•ŠìŒ - ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨ê°€ ì „ì²´ ì„¸ì…˜ì„ ì¢…ë£Œì‹œí‚¤ì§€ ì•Šë„ë¡
    }
  }

  /// ì¬ìƒ ì¤‘ì§€
  Future<void> stopPlaying() async {
    if (!_isPlaying) {
      return;
    }

    await _player.stop();
    _isPlaying = false;
    print('ì¬ìƒ ì¤‘ì§€');
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  Future<void> dispose() async {
    _bufferFlushTimer?.cancel();
    _fullResponseBuffer.clear();
    _audioBuffer.clear();
    await stopRecording();
    await stopPlaying();
    await _recordingSubscription?.cancel();
    await _recorder.dispose();
    await _player.dispose();
    await _audioStreamController.close();
    await _playbackCompletedController.close();
  }
}
